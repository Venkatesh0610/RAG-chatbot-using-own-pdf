
# AskYourPDF: FastAPI-Powered RAG Chatbot with Groq + FAISS

This project implements an end-to-end **Retrieval-Augmented Generation (RAG)** pipeline that lets users **upload PDFs and ask questions** about their content. Itâ€™s powered by:

* âš™ï¸ **FastAPI** for a blazing-fast backend
* ğŸ§  **Groq (LLaMA 3)** for intelligent language understanding
* ğŸ“„ **PDF Upload + Chunking** for ingesting documents
* ğŸ“š **FAISS + HuggingFace Embeddings** for vector search
* ğŸ” **History-Aware Rewriting** to make follow-ups context-rich

> Donâ€™t just search your PDFs â€” *converse* with them intelligently.

---

**Check out the blog for detailed understanding :** [RAG chatbot using Langchain](https://medium.com/@avenkatesh0610)

---

## ğŸš€ Features

* ğŸ“„ Upload and embed your PDFs
* ğŸ§  Ask questions, get answers from your content
* ğŸ” If no context is found, intelligently rewrite the query
* âœ¨ Powered by Groq for ultra-low latency responses
* ğŸ”— Chunked PDF text stored using FAISS for fast retrieval
* ğŸ”§ Simple FastAPI backend and minimal chatbot UI (HTML)

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py                  # FastAPI backend + RAG logic
â”œâ”€â”€ chatbot_ui.html         # Frontend chat interface
â”œâ”€â”€ temp_uploads/           # Folder to store uploaded PDFs
â”œâ”€â”€ vectors/                # Local FAISS index + embeddings
â”œâ”€â”€ requirements.txt        # All Python dependencies
```

---

## ğŸ”„ RAG Chatbot Flow

<img width="1500" height="511" alt="image" src="https://github.com/user-attachments/assets/78cc543d-6998-44cb-8147-b4680edf0c52" />

<img width="1816" height="521" alt="image" src="https://github.com/user-attachments/assets/e6084540-5ad4-4e9a-88ed-e09cdcc70f36" />

---

## âš™ï¸ Local Setup Instructions

Follow these steps to run the project locally:

```bash
**1. Clone the repository**

git clone https://github.com/Venkatesh0610/RAG-chatbot-using-own-pdf.git
cd RAG-chatbot-using-own-pdf

**2. Create and activate virtual environment**

python -m venv venv
source venv/bin/activate    # For Linux/macOS
venv\Scripts\activate       # For Windows

**3. Install required dependencies**

pip install -r requirements.txt

**4. Start the FastAPI server**

uvicorn app:app --reload --port 8080

**5. Open the chatbot UI**

Visit http://localhost:8080/ in your browser
```

---

## ğŸ’¬ Example

> **User**: What are transformers?

> **System**: Transformers are neural network architectures based on self-attention mechanisms, widely used in NLP tasks such as translation, summarization, and question-answering.

---


## ğŸ™Œ Conclusion

In this project, we built an end-to-end PDF Question-Answering RAG system using FastAPI, FAISS, HuggingFace Embeddings, and Groq's blazing-fast LLaMA3 model. From PDF upload to chunking, embedding, retrieval, and final response generation â€” every step is streamlined and modular.

If you liked this, give it a **star**,and follow my [Blog](https://medium.com/@avenkatesh0610) and [Youtube](https://www.youtube.com/@avenkatesh0610) for more.
